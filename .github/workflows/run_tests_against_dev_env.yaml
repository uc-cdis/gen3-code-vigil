# Uses the shared workflow from this repo for ease of maintenance
name: Run tests against dev environment

on:
  workflow_call:
    inputs:
      NAMESPACE:
        description: 'Namespace for the dev env'
        required: true
        type: string
      TEST_LABELS:
        description: 'Test labels to determine which tests to run'
        required: false
        type: string
    secrets:
      CI_SLACK_BOT_TOKEN:
        required: true
      EKS_CLUSTER_NAME:
        required: false

permissions:
  id-token: write
  contents: read
  pull-requests: write
  issues: write

jobs:
  create:
    runs-on: ubuntu-latest

    defaults:
      run:
        working-directory: "gen3-code-vigil/gen3-integration-tests"

    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      REPO: ${{ github.event.repository.name }}
      REPO_FN: ${{ github.event.repository.full_name }}
      BRANCH: ${{ github.event.pull_request.head.ref }}
      PR_NUM: ${{ github.event.pull_request.number }}
      COMMIT_SHA: ${{ github.event.pull_request.head.sha }}
      RUN_NUM: ${{ github.run_number }}
      RUN_ID: ${{ github.run_id }}
      ATTEMPT_NUM: ${{ github.run_attempt }}
      CI_SLACK_BOT_TOKEN: ${{ secrets.CI_SLACK_BOT_TOKEN }}
      EKS_CLUSTER_NAME : ${{ secrets.EKS_CLUSTER_NAME }}
      NAMESPACE: ${{ inputs.NAMESPACE }}
      TEST_LABEL: ${{ inputs.TEST_LABELS }}
      WORKING_DIR: gen3-code-vigil/gen3-integration-tests
      SLACK_CHANNEL: "#test-bots"
      GH_WORKSPACE: ${{ github.workspace }}
    steps:
      - name: Checkout integration test code
        uses: actions/checkout@v4
        with:
          repository: uc-cdis/gen3-code-vigil
          path: gen3-code-vigil

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.17'

      - name: Set Up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: latest

      - name: Set Up Helm
        uses: azure/setup-helm@v4.3.0
        with:
          version: latest

      - name: Install dependencies
        env:
          YQ_VERSION: v4.45.2
          YQ_BINARY: yq_linux_amd64
        run: |
          sudo rm -f /etc/apt/sources.list.d/github_git-lfs.list
          sudo apt update && sudo apt install wget -y
          sudo wget https://raw.githubusercontent.com/dwyl/english-words/master/words.txt -O /usr/share/dict/words
          sudo wget https://github.com/mikefarah/yq/releases/download/${YQ_VERSION}/${YQ_BINARY}.tar.gz -O - |\
          tar xz && sudo mv ${YQ_BINARY} /usr/bin/yq
          python -m pip install --upgrade pip
          if [[ "$REPO" == "data-simulator" ]]; then
            sed -i "s|\(data-simulator[[:space:]]*=[[:space:]]*{[^}]*rev[[:space:]]*=[[:space:]]*\"\)[^\"]*\(.*\)|\1$BRANCH\2|" pyproject.toml
          fi
          if [[ "$REPO" == "gen3sdk-python" ]]; then
            sed -i "s|^gen3 = \".*\"|gen3 = { git = \"https://github.com/uc-cdis/gen3sdk-python\", rev = \"$BRANCH\" }|" pyproject.toml
          fi
          pip install poetry
          poetry lock
          poetry install
          poetry show
          sudo apt update && poetry run playwright install-deps && poetry run playwright install --with-deps chromium
          sudo apt install openjdk-11-jre -y

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
            role-to-assume: arn:aws:iam::707767160287:role/github-action-role
            role-session-name: GitHub_to_AWS_via_FederatedOIDC
            aws-region: "us-east-1"
            role-duration-seconds: 7200

      - name: Update kube config
        run: |
          aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER_NAME }} --region "us-east-1"

      - name: Prepare CI environment
        id: prep_ci_env
        continue-on-error: true  # if this fails, we still need to run clean-up steps
        run: |
            mkdir $HOME/.gen3
            mkdir logs
            echo "****** Prepare CI Environment ******" > logs/gh_action_logs.txt
            ./gen3_ci/scripts/generate_api_keys.sh test_data/test_setup/users.csv ${NAMESPACE}.dev.planx-pla.net ${NAMESPACE}

      - name: Get test labels
        id: get_test_labels
        continue-on-error: true  # if this fails, we still need to run clean-up steps
        run: |
            if [[ -n $TEST_LABELS ]]; then
                test_label_expr="${TEST_LABELS//,/ or }"
                test_label="-k \"$test_label_expr\""
            else
                if [[ "$GITHUB_EVENT_NAME" == "pull_request" ]]; then
                test_label=$(gh api repos/$REPO_FN/pulls/$PR_NUM --jq '.labels | map(select(.name | test("^(?i)test"))) | map(.name) | if length > 0 then "-k \"" + join(" or ") + "\"" else "" end')
                fi
            fi
            echo $test_label
            echo "TEST_LABEL=$test_label" >> $GITHUB_ENV

      - name: Run tests
        id: run_tests
        continue-on-error: true  # if this fails, we still need to run clean-up steps
        run: |
            echo -e "\n\n************ Run tests ************" >> logs/gh_action_logs.txt
            mkdir output
            poetry run pytest -n logical -m "not wip" --alluredir allure-results --no-header --dist loadscope ${{ env.TEST_LABEL }} >> logs/gh_action_logs.txt 2>&1
            if [ $? -ne 0 ]; then
                echo "PR_ERROR_MSG=Test(s) failures encountered in PR" >> $GITHUB_ENV
            fi

      - name: Generate allure report
        id: generate_allure_report
        if: ${{ steps.run_tests.outcome == 'success' || steps.run_tests.outcome == 'failure' }}
        continue-on-error: true  # if this fails, we still need to run clean-up steps
        run: |
            npm install -g allure-commandline --save-dev
            allure generate allure-results -o allure-report --clean
            if [ $? -ne 0 ]; then
                echo "PR_ERROR_MSG=Failed to generate allure report" >> $GITHUB_ENV
            fi

      - name: Upload allure report to S3
        id: upload_allure_report
        if: ${{ steps.generate_allure_report.outcome == 'success' }}
        continue-on-error: true  # if this fails, we still need to run clean-up steps
        run: |
            echo -e "\n\n******* Upload reports to S3 *******" >> logs/gh_action_logs.txt
            if [[ "$IS_NIGHTLY_RUN" == "true" ]]; then
                DATE=$(date +%Y%m%d)
                aws s3 sync ./allure-report s3://ci-allure-reports/nightly-run/$DATE >> logs/gh_action_logs.txt 2>&1
            else
                aws s3 sync ./allure-report s3://ci-allure-reports/$REPO/$PR_NUM/$RUN_NUM/$ATTEMPT_NUM >> logs/gh_action_logs.txt 2>&1
            fi
            if [ $? -ne 0 ]; then
                echo "PR_ERROR_MSG=Failed to upload allure report to s3 bucket" >> $GITHUB_ENV
            fi

      - name: Upload logs to S3
        id: upload_gh_action_logs
        continue-on-error: true  # if this fails, we still need to run clean-up steps
        run: |
            echo -e "\n\n******** Upload logs to S3 ********" >> logs/gh_action_logs.txt
            if [[ "$IS_NIGHTLY_RUN" == "true" ]]; then
                DATE=$(date +%Y%m%d)
                aws s3 sync ./logs s3://ci-allure-reports/nightly-run/$DATE >> logs/gh_action_logs.txt 2>&1
            else
                aws s3 sync ./logs s3://ci-allure-reports/$REPO/$PR_NUM/$RUN_NUM/$ATTEMPT_NUM >> logs/gh_action_logs.txt 2>&1
            fi
            if [ $? -ne 0 ]; then
                echo "PR_ERROR_MSG=Failed to upload allure report to s3 bucket" >> $GITHUB_ENV
            fi

      - name: Generate markdown report
        id: generate_md_report
        if: ${{ steps.upload_allure_report.outcome == 'success' || steps.upload_gh_action_logs.outcome == 'success' }}
        continue-on-error: true
        # It is possible for env is prepped but tests error out, the pod logs will help in debugging env issues
        run: |
            if [ -n "${{ env.PR_ERROR_MSG }}" ]; then
                if [ ! -f output/report.md ]; then
                mkdir output
                touch output/report.md
                fi
                echo -e "\n${{ env.PR_ERROR_MSG }}" >> output/report.md
            fi
            if [ "${{ steps.upload_allure_report.outcome }}" == "success" ]; then
                if [[ "$IS_NIGHTLY_RUN" == "true" ]]; then
                DATE=$(date +%Y%m%d)
                echo -e "\nPlease find the detailed integration test report [here](https://allure.ci.planx-pla.net/nightly-run/$DATE/index.html)" >> output/report.md
                else
                echo -e "\nPlease find the detailed integration test report [here](https://allure.ci.planx-pla.net/$REPO/$PR_NUM/$RUN_NUM/$ATTEMPT_NUM/index.html)" >> output/report.md
                fi
            fi
            if [ "${{ steps.upload_gh_action_logs.outcome }}" == "success" ]; then
                if [[ "$IS_NIGHTLY_RUN" == "true" ]]; then
                DATE=$(date +%Y%m%d)
                echo -e "\nPlease find the Github Action logs [here](https://allure.ci.planx-pla.net/nightly-run/$DATE/gh_action_logs.txt)" >> output/report.md
                else
                echo -e "\nPlease find the Github Action logs [here](https://allure.ci.planx-pla.net/$REPO/$PR_NUM/$RUN_NUM/$ATTEMPT_NUM/gh_action_logs.txt)" >> output/report.md
                fi
            fi

      - name: Render report to the PR
        id: publish_md_report
        if: ${{ github.event_name == 'pull_request' && (steps.upload_allure_report.outcome == 'success' || steps.upload_gh_action_logs.outcome == 'success') }}
        continue-on-error: true  # if this fails, we still need to run clean-up steps
        run: gh pr comment $PR_NUM --body-file output/report.md -R $REPO_FN
        env:
            GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Generate Slack report
        id: generate_slack_report
        if: ${{ steps.upload_allure_report.outcome == 'success' || steps.upload_gh_action_logs.outcome == 'success' }}
        continue-on-error: true # if this fails, we still need to run clean-up steps
        run: poetry run python -m gen3_ci.scripts.generate_slack_report

      - name: Publish report to Slack
        id: slack_notify
        if: ${{ steps.generate_slack_report.outcome == 'success' }}
        continue-on-error: true  # if this fails, we still need to run clean-up steps
        uses: slackapi/slack-github-action@v2.0.0
        with:
            method: chat.postMessage
            token: ${{ env.CI_SLACK_BOT_TOKEN }}
            payload-file-path: "./${{ env.WORKING_DIR }}/slack_report.json"
            payload-templated: true

      - name: Mark workflow as failed for unsuccessful test runs
        if: ${{ steps.run_tests.outcome != 'success' }}
        run: echo "Test run was unsuccessful, marking workflow as failed" && exit 1
