name: Integration Tests

on:
  workflow_call:
    inputs:
      # needed to be set if repo name differs in quay
      QUAY_REPO:
        required: false
        type: string
      # set this for service PRs to select tests pertaining to the service under test
      # must match the marker used for the service, please look at the `markers` section of pyproject.toml
      SERVICE_TO_TEST:
        required: false
        type: string
    secrets:
      CI_AWS_ACCESS_KEY_ID:
        required: true
      CI_AWS_SECRET_ACCESS_KEY:
        required: true
      JENKINS_API_TOKEN:
        required: true
      QA_DASHBOARD_S3_PATH:
        required: true


concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
    integration_tests:
        runs-on: ubuntu-latest

        defaults:
          run:
            # the test directory in gen3-code-vigil
            working-directory: gen3-integration-tests

        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          JENKINS_URL: "https://jenkins.planx-pla.net"
          JENKINS_USERNAME: "PlanXCyborg"
          JENKINS_PASSWORD: ${{ secrets.JENKINS_API_TOKEN }}
          REPO: ${{ github.event.repository.name }}
          REPO_FN: ${{ github.event.repository.full_name }}
          BRANCH: ${{ github.event.pull_request.head.ref }}
          PR_NUM: ${{ github.event.pull_request.number }}
          PR_LABELS: ${{ toJson(github.event.pull_request.labels.*.name) }}
          COMMIT_SHA: ${{ github.event.pull_request.head.sha }}
          COMMIT_TIME: ${{ github.event.pull_request.head.repo.pushed_at }}
          RUN_NUM: ${{ github.run_number }}

        steps:
          # # Enable step debugging. Uncomment this to debug pipeline issues
          # - name: Enable Step Debugging
          #   run: echo "ACTIONS_STEP_DEBUG=true >> $GITHUB_ENV"

          # Checkout current branch of gen3-code-vigil if it is the repo under test
          - name: Checkout integration test code from dev branch
            if: ${{ github.event.repository.name == 'gen3-code-vigil' }}
            uses: actions/checkout@v4

          # Checkout master branch of gen3-code-vigil when another repo is under test
          - name: Checkout integration test code from master branch
            if: ${{ github.event.repository.name  != 'gen3-code-vigil' }}
            uses: actions/checkout@v4
            with:
              repository: uc-cdis/gen3-code-vigil
              ref: master

          # gen3-integration-tests run with python 3.9
          - name: Set up Python
            uses: actions/setup-python@v4
            with:
              python-version: 3.9

          # allure report generation needs node
          - name: Set up node
            uses: actions/setup-node@v3

          # Install gen3-integration-tests dependencies
          # wamerican: data-simulator needs "/usr/share/dict/words" to generate data that isn't random strings
          - name: Install dependencies
            run: |
              sudo apt-get install -y --reinstall wamerican
              python -m pip install --upgrade pip
              pip install poetry
              poetry install
              poetry show
              poetry run playwright install

          # TODO: Rely on a database in AWS to make this faster
          # Select an unlocked environment
          # If an env is specified in a PR label use it, else pick one from the pool
          - name: Select CI environment
            id: select_ci_env
            run: |
              labels="${PR_LABELS//\\n/ }"
              env_label=$(echo "$labels" | jq -r 'map(select(test("jenkins-"; "i"))) | first')
              if [[ $env_label != "" && $env_label != null ]]; then
                echo "Found PR label $env_label"
                poetry run python -m gen3_ci.scripts.select_ci_environment $env_label
              else
                poetry run python -m gen3_ci.scripts.select_ci_environment
              fi

          # TODO: Improve the logic to do differential updates to the env, not roll all services
          # Apply the changes to the manifest of the selected CI environment, roll the pods and run usersync
          # Generate API keys for test users for the environment
          - name: Prepare CI environment
            id: prep_ci_env
            if: ${{ env.NAMESPACE != 'None' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              mkdir $HOME/.gen3
              poetry run python -m gen3_ci.scripts.prepare_ci_environment

          - name: Run tests pertaining to specific service
            id: run_service_tests
            if: ${{ inputs.SERVICE_TO_TEST && steps.prep_ci_env.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              mkdir output
              poetry run pytest -n auto -m "not wip" -m ${{ inputs.SERVICE_TO_TEST }} --clean-alluredir --alluredir allure-results --no-header

          - name: Run tests
            id: run_tests
            if: ${{ !inputs.SERVICE_TO_TEST && steps.prep_ci_env.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              mkdir output
              poetry run pytest -n auto -m "not wip" --clean-alluredir --alluredir allure-results --no-header

          - name: Debug logging
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              echo steps.run_service_tests.outcome = ${{ steps.run_service_tests.outcome }}
              echo steps.run_tests.outcome = ${{ steps.run_tests.outcome }}

          - name: Generate allure report
            id: generate_allure_report
            if: ${{ steps.run_service_tests.outcome == 'success' || steps.run_service_tests.outcome == 'failure' || steps.run_tests.outcome == 'success' || steps.run_tests.outcome == 'failure' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              npm install -g allure-commandline --save-dev
              allure generate allure-results -o allure-report --clean

          - name: Render md report to the PR
            id: generate_md_report
            if: ${{ steps.run_service_tests.outcome == 'success' || steps.run_service_tests.outcome == 'failure' || steps.run_tests.outcome == 'success' || steps.run_tests.outcome == 'failure' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: gh pr comment $PR_NUM --body-file output/report.md -R $REPO_FN
            env:
              GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

          - name: Upload allure report to S3
            id: upload_allure_report
            if: ${{ steps.generate_allure_report.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: aws s3 sync ./allure-report ${{ secrets.QA_DASHBOARD_S3_PATH }}/$REPO/$PR_NUM/$RUN_NUM
            env:
              AWS_ACCESS_KEY_ID: ${{ secrets.CI_AWS_ACCESS_KEY_ID }}
              AWS_SECRET_ACCESS_KEY: ${{ secrets.CI_AWS_SECRET_ACCESS_KEY }}
              AWS_DEFAULT_REGION: 'us-east-1'

          - name: Publish allure report link to the PR
            id: gh_comment_allure_link
            if: ${{ steps.upload_allure_report.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: gh pr comment $PR_NUM --body "Please find the detailed integration test report [here](https://qa.planx-pla.net/dashboard/Secure/gen3-ci-reports/$REPO/$PR_NUM/$RUN_NUM/index.html)" -R $REPO_FN
            env:
              GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

          - name: Archive pod logs from CI environment
            id: archive_pod_logs
            if: ${{ steps.prep_ci_env.outcome == 'success' || steps.prep_ci_env.outcome == 'failure' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: poetry run python -m gen3_ci.scripts.save_ci_env_pod_logs

          - name: Publish pod logs url to the PR
            id: gh_comment_pod_logs_link
            if: ${{ steps.archive_pod_logs.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: gh pr comment $PR_NUM --body "Please find the ci env pod logs [here]($POD_LOGS_URL)" -R $REPO_FN
            env:
              GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

          - name: Release CI environment
            id: release_ci_env
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: poetry run python -m gen3_ci.scripts.release_ci_environment

          - name: Mark workflow as failed for unsuccessful test runs
            if: ${{ steps.run_service_tests.outcome != 'success' && steps.run_tests.outcome != 'success' }}
            run: echo "Test run was unsuccessful, marking workflow as failed" && exit 1

          - name: Stop pending jenkins jobs for cancelled run
            if: ${{ cancelled() }}
            run: poetry run python -m gen3_ci.scripts.clean_up_jenkins
