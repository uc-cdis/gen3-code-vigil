name: Integration Tests

on:
  workflow_call:
    inputs:
      # needed to be set if repo name differs in quay
      QUAY_REPO:
        required: false
        type: string
      # set this for service PRs to select tests pertaining to the service under test
      # must match the marker used for the service, please look at the `markers` section of pyproject.toml
      SERVICE_TO_TEST:
        required: false
        type: string
      TEST_REPO_BRANCH:
        required: false
        type: string
        default: master
      CLOUD_AUTO_BRANCH:
        required: false
        type: string
        default: master
    secrets:
      CI_AWS_ACCESS_KEY_ID:
        required: true
      CI_AWS_SECRET_ACCESS_KEY:
        required: true
      JENKINS_API_TOKEN:
        required: true
      QA_DASHBOARD_S3_PATH:
        required: true
      CI_TEST_ORCID_USERID:
        required: true
      CI_TEST_ORCID_PASSWORD:
        required: true
      CI_TEST_RAS_USERID:
        required: true
      CI_TEST_RAS_PASSWORD:
        required: true
      CI_TEST_RAS_2_USERID:
        required: true
      CI_TEST_RAS_2_PASSWORD:
        required: true
      CI_SLACK_BOT_TOKEN:
        required: true
      CI_SLACK_CHANNEL_ID:
        required: true

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
    integration_tests:
        runs-on: ubuntu-latest

        defaults:
          run:
            # the test directory in gen3-code-vigil
            working-directory: gen3-integration-tests

        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          JENKINS_URL: "https://jenkins.planx-pla.net"
          JENKINS_USERNAME: "PlanXCyborg"
          JENKINS_PASSWORD: ${{ secrets.JENKINS_API_TOKEN }}
          REPO: ${{ github.event.repository.name }}
          REPO_FN: ${{ github.event.repository.full_name }}
          BRANCH: ${{ github.event.pull_request.head.ref }}
          PR_NUM: ${{ github.event.pull_request.number }}
          COMMIT_SHA: ${{ github.event.pull_request.head.sha }}
          RUN_NUM: ${{ github.run_number }}
          CI_TEST_ORCID_USERID: ${{ secrets.CI_TEST_ORCID_USERID }}
          CI_TEST_ORCID_PASSWORD: ${{ secrets.CI_TEST_ORCID_PASSWORD }}
          CI_TEST_RAS_USERID: ${{ secrets.CI_TEST_RAS_USERID }}
          CI_TEST_RAS_PASSWORD: ${{ secrets.CI_TEST_RAS_PASSWORD }}
          CI_TEST_RAS_2_USERID: ${{ secrets.CI_TEST_RAS_2_USERID }}
          CI_TEST_RAS_2_PASSWORD: ${{ secrets.CI_TEST_RAS_2_PASSWORD }}
          CLOUD_AUTO_BRANCH: ${{ inputs.CLOUD_AUTO_BRANCH }}
          SLACK_CHANNEL: ${{ secrets.CI_SLACK_CHANNEL_ID }}
          SFTP_QA_HOSTNAME: "sftp-qa.planx-pla.net"
          SFTP_QA_HOSTNAME_2: "s-5745d53f10e1421eb.server.transfer.us-east-1.amazonaws.com"


        steps:
          # Ensure the PR is run under the same org as an Internal PR
          # and not by external forks/PRs
          - name: Check if PR is from the same organization
            if: github.repository_owner != github.event.pull_request.head.repo.owner.login
            run:  |
              echo "Skip pull requests from repositories not within the same organization"
              echo "SKIP_TESTS=true" >> $GITHUB_ENV

          # Dependabot PRs cannot run tests as they cannot access all secrets
          - name: Re-trigger dependabot PRs
            if: startsWith(env.BRANCH, 'dependabot/')
            working-directory: ${{ github.workspace }}
            run: |
              gh pr comment $PR_NUM --body "@dependabot rebase"
              echo "SKIP_TESTS=true" >> $GITHUB_ENV

          # Skip integration tests when the following PR labels are present:
          # not-ready-for-ci / decommission-environment
          - name: Skip integration tests for specific PR labels
            if: ${{ env.SKIP_TESTS != 'true' }}
            working-directory: ${{ github.workspace }}
            run: |
              if gh api repos/$REPO_FN/pulls/$PR_NUM --jq '.labels | map(.name) | .[] | select(. == "not-ready-for-ci" or . == "release-notes" or . == "decommission-environment")' | grep -q .; then
                  echo "Skipping CI since one of the PR labels is present - not-ready-for-ci / decommission-environment"
                  echo "SKIP_TESTS=true" >> $GITHUB_ENV
              fi

          # Nightly builds have a label "nightly-run" and are reported on "nightly-builds channel"
          - name: Handle nightly build reporting
            working-directory: ${{ github.workspace }}
            if: ${{ env.SKIP_TESTS != 'true' }}
            run: |
              nightly_label=$(gh api repos/$REPO_FN/pulls/$PR_NUM --jq '.labels | map(select(.name | startswith("nightly"))) | .[0].name')
              echo "$nightly_label"
              if [[ -n $nightly_label ]]; then
                  echo "IS_NIGHTLY_RUN=true" >> $GITHUB_ENV
              fi

          # Checkout current repo
          - name: Checkout current repo
            if: ${{ env.SKIP_TESTS != 'true' }}
            uses: actions/checkout@v4

          # Skip tests when there are only markdown files
          - name: Skip integration tests if PR contains only Markdown files
            if: ${{ env.SKIP_TESTS != 'true' }}
            working-directory: ${{ github.workspace }}
            run: |
              git fetch -q
              FILE_TYPES=$(git diff --name-only origin/${{ github.base_ref }} HEAD | grep -v '@' | awk -F . '{print $NF}' | sort -u)
              echo $FILE_TYPES

              # Check if the only file type is markdown
              if [[ "$FILE_TYPES" == "md" ]]; then
                echo "All files are markdown, skipping step."
                echo "SKIP_TESTS=true" >> $GITHUB_ENV
              fi

          # Checkout master branch of gen3-code-vigil when another repo is under test
          - name: Checkout integration test code
            if: ${{ env.SKIP_TESTS != 'true' && github.event.repository.name  != 'gen3-code-vigil' }}
            uses: actions/checkout@v4
            with:
              repository: uc-cdis/gen3-code-vigil
              ref: ${{ inputs.TEST_REPO_BRANCH }}

          # gen3-integration-tests run with python 3.9
          - name: Set up Python
            if: ${{ env.SKIP_TESTS != 'true' }}
            uses: actions/setup-python@v5
            with:
              python-version: '3.9'

          - name: Set up Go
            if: ${{ env.SKIP_TESTS != 'true' }}
            uses: actions/setup-go@v5
            with:
              go-version: '1.17'

          # allure report generation needs node
          - name: Set up node
            if: ${{ env.SKIP_TESTS != 'true' }}
            uses: actions/setup-node@v4
            with:
              node-version: 20

          # Install gen3-integration-tests dependencies
          # wamerican: data-simulator needs "/usr/share/dict/words" to generate data that isn't random strings
          - name: Install dependencies
            if: ${{ env.SKIP_TESTS != 'true' }}
            run: |
              sudo apt-get install -y --reinstall wamerican
              python -m pip install --upgrade pip
              pip install poetry
              poetry install
              poetry show
              poetry run playwright install chromium

          - name: Get commit time
            if: ${{ env.SKIP_TESTS != 'true' }}
            run: |
              commit_time=$(gh api repos/$REPO_FN/commits/$COMMIT_SHA | jq -r '.commit.committer.date')
              echo "COMMIT_TIME=$commit_time" >> $GITHUB_ENV

          # Workaround for Paramiko RejectPolicy: pre-load the SFTP host key to avoid connection failure during dbGaP user sync
          # Without this, Paramiko will reject the host since known_hosts is empty in CI
          - name: Add SFTP host key to known_hosts
            if: ${{ env.SKIP_TESTS != 'true' }}
            run: |
              mkdir -p ~/.ssh
              ssh-keyscan -p 22 $SFTP_QA_HOSTNAME >> ~/.ssh/known_hosts
              ssh-keyscan -p 22 $SFTP_QA_HOSTNAME_2 >> ~/.ssh/known_hosts

          # TODO: Rely on a database in AWS to make this faster
          # Select an unlocked environment
          # If an env is specified in a PR label use it, else pick one from the pool
          - name: Select CI environment
            if: ${{ env.SKIP_TESTS != 'true' }}
            id: select_ci_env
            run: |
              env_label=$(gh api repos/$REPO_FN/pulls/$PR_NUM --jq '.labels | map(select(.name | startswith("jenkins-"))) | .[0].name')
              echo "$env_label"
              if [[ $env_label != "" && $env_label != null ]]; then
                echo "Found PR label $env_label"
                poetry run python -m gen3_ci.scripts.select_ci_environment $env_label
              else
                poetry run python -m gen3_ci.scripts.select_ci_environment
              fi
              if [ $? -ne 0 ]; then
                echo "PR_ERROR_MSG=Failed to select CI environment" >> $GITHUB_ENV
              fi


          - name: Get modified folders
            # This is applicable for Manifest PRs only
            id: get_modified_folders
            env:
              QUAY_REPO: ${{ inputs.QUAY_REPO }}
            if: ${{ env.SKIP_TESTS != 'true' && (github.event.repository.name == 'cdis-manifest' || github.event.repository.name == 'gitops-qa') }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              PR_FILES=$(gh api repos/$REPO_FN/pulls/$PR_NUM/files --jq '.[].filename')
              UPDATED_FOLDERS=$(echo "$PR_FILES" | grep '/.*' | sed 's|/.*||' | grep -v "^.github$" | uniq | sort -u | tr '\n' ',' | sed 's/,$//')
              echo "UPDATED_FOLDERS=$UPDATED_FOLDERS" >> $GITHUB_ENV

          # TODO: Improve the logic to do differential updates to the env, not roll all services
          # Apply the changes to the manifest of the selected CI environment, roll the pods and run usersync
          # Generate API keys for test users for the environment
          - name: Prepare CI environment
            id: prep_ci_env
            env:
              QUAY_REPO: ${{ inputs.QUAY_REPO }}
            if: ${{ env.SKIP_TESTS != 'true' && steps.select_ci_env.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              echo $UPDATED_FOLDERS
              mkdir $HOME/.gen3
              poetry run python -m gen3_ci.scripts.prepare_ci_environment
              if [ $? -ne 0 ]; then
                echo "PR_ERROR_MSG=Failed to Prepare CI environment" >> $GITHUB_ENV
              fi

          # This is used for running specific test suites by labeling the PR with the test class
          # Multiple suites can be executed by adding multiple labels
          - name: Get test labels
            id: get_test_labels
            if: ${{ env.SKIP_TESTS != 'true' && steps.prep_ci_env.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              test_label=$(gh api repos/$REPO_FN/pulls/$PR_NUM --jq '.labels | map(select(.name | startswith("Test"))) | map(.name) | if length > 0 then "-k \"" + join(" or ") + "\"" else "" end')
              echo $test_label
              echo "TEST_LABEL=$test_label" >> $GITHUB_ENV

          - name: Run tests pertaining to specific service
            id: run_service_tests
            if: ${{ env.SKIP_TESTS != 'true' && inputs.SERVICE_TO_TEST && steps.prep_ci_env.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              mkdir output
              GEN3_INSTANCE_TYPE="ADMINVM_REMOTE" poetry run pytest -n auto -m "${{ inputs.SERVICE_TO_TEST }} and not wip" --alluredir allure-results --no-header --dist loadscope ${{ env.TEST_LABEL }}
              if [ $? -ne 0 ]; then
                echo "PR_ERROR_MSG=Test(s) failures encountered in PR" >> $GITHUB_ENV
              fi

          - name: Run tests
            id: run_tests
            if: ${{ env.SKIP_TESTS != 'true' && !inputs.SERVICE_TO_TEST && steps.prep_ci_env.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              mkdir output
              GEN3_INSTANCE_TYPE="ADMINVM_REMOTE" poetry run pytest -n auto -m "not wip" --alluredir allure-results --no-header --dist loadscope ${{ env.TEST_LABEL }}
              if [ $? -ne 0 ]; then
                echo "PR_ERROR_MSG=Test(s) failures encountered in PR" >> $GITHUB_ENV
              fi

          - name: Debug logging
            if: ${{ env.SKIP_TESTS != 'true' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              echo steps.run_service_tests.outcome = ${{ steps.run_service_tests.outcome }}
              echo steps.run_tests.outcome = ${{ steps.run_tests.outcome }}

          - name: Generate allure report
            id: generate_allure_report
            if: ${{ env.SKIP_TESTS != 'true' && steps.run_service_tests.outcome == 'success' || steps.run_service_tests.outcome == 'failure' || steps.run_tests.outcome == 'success' || steps.run_tests.outcome == 'failure' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              npm install -g allure-commandline --save-dev
              allure generate allure-results -o allure-report --clean
              if [ $? -ne 0 ]; then
                echo "PR_ERROR_MSG=Failed to generate allure report" >> $GITHUB_ENV
              fi

          - name: Upload allure report to S3
            id: upload_allure_report
            if: ${{ env.SKIP_TESTS != 'true' && steps.generate_allure_report.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: |
              aws s3 sync ./allure-report ${{ secrets.QA_DASHBOARD_S3_PATH }}/$REPO/$PR_NUM/$RUN_NUM
              if [ $? -ne 0 ]; then
                echo "PR_ERROR_MSG=Failed to upload allure report to s3 bucket" >> $GITHUB_ENV
              fi
            env:
              AWS_ACCESS_KEY_ID: ${{ secrets.CI_AWS_ACCESS_KEY_ID }}
              AWS_SECRET_ACCESS_KEY: ${{ secrets.CI_AWS_SECRET_ACCESS_KEY }}
              AWS_DEFAULT_REGION: 'us-east-1'

          - name: Archive pod logs from CI environment
            id: archive_pod_logs
            if: ${{ env.SKIP_TESTS != 'true' && steps.prep_ci_env.outcome == 'success' || steps.prep_ci_env.outcome == 'failure' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: poetry run python -m gen3_ci.scripts.save_ci_env_pod_logs

          - name: Generate markdown report
            id: generate_md_report
            if: ${{ env.SKIP_TESTS != 'true' && steps.generate_allure_report.outcome == 'success' || steps.archive_pod_logs.outcome == 'success' }}
            continue-on-error: true
            # It is possible for env is prepped but tests error out, the pod logs will help in debugging env issues
            run: |
              if [ -n "${{ env.PR_ERROR_MSG }}" ]; then
                echo -e "\n${{ env.PR_ERROR_MSG }}" >> output/report.md
              fi
              if [ "${{ steps.upload_allure_report.outcome }}" == "success" ]; then
                echo -e "\nPlease find the detailed integration test report [here](https://qa.planx-pla.net/dashboard/Secure/gen3-ci-reports/$REPO/$PR_NUM/$RUN_NUM/index.html)" >> output/report.md
                echo -e "\nLogin [here](https://qa.planx-pla.net/login)" >> output/report.md
              fi
              if [ "${{steps.archive_pod_logs.outcome}}" == "success" ]; then
                if [ ! -d output ]; then
                  mkdir output
                fi
                if [ ! -f "output/report.md" ]; then
                  touch "output/report.md"
                fi
                echo -e "\nPlease find the ci env pod logs [here]($POD_LOGS_URL)" >> output/report.md
              fi

          - name: Render report to the PR
            id: publish_md_report
            if: ${{ env.SKIP_TESTS != 'true' && steps.generate_allure_report.outcome == 'success' || steps.archive_pod_logs.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: gh pr comment $PR_NUM --body-file output/report.md -R $REPO_FN
            env:
              GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

          - name: Generate Slack report
            id: generate_slack_report
            if: ${{ env.SKIP_TESTS != 'true' && steps.generate_allure_report.outcome == 'success' || steps.archive_pod_logs.outcome == 'success' }}
            continue-on-error: true # if this fails, we still need to run clean-up steps
            run: poetry run python -m gen3_ci.scripts.generate_slack_report

          - name: Publish report to Slack
            id: slack_notify
            if: ${{ env.SKIP_TESTS != 'true' && steps.publish_md_report.outcome == 'success' }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            uses: slackapi/slack-github-action@v2.0.0
            with:
              method: chat.postMessage
              token: ${{ secrets.CI_SLACK_BOT_TOKEN }}
              payload-file-path: "./gen3-integration-tests/slack_report.json"
              payload-templated: true

          - name: Release CI environment
            id: release_ci_env
            if: ${{ env.SKIP_TESTS != 'true' && steps.select_ci_env.outcome == 'success' || cancelled() }}
            continue-on-error: true  # if this fails, we still need to run clean-up steps
            run: poetry run python -m gen3_ci.scripts.release_ci_environment

          - name: Mark workflow as failed for unsuccessful test runs
            if: ${{ env.SKIP_TESTS != 'true' && steps.run_service_tests.outcome != 'success' && steps.run_tests.outcome != 'success' }}
            run: echo "Test run was unsuccessful, marking workflow as failed" && exit 1

          - name: Stop pending jenkins jobs for cancelled run
            if: ${{ env.SKIP_TESTS != 'true' && cancelled() }}
            run: poetry run python -m gen3_ci.scripts.clean_up_jenkins
